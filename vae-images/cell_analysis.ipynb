{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Training - Faces dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from model.VariationalAutoencoder import VariationalAutoencoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, save_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = os.environ.get('HOME') + '/model1'\n",
    "FILE_MODEL = 'weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder()\n",
    "vae.model.load_weights(os.path.join(MODEL_FOLDER, 'weights.h5'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image format: PNG\nimage mode: RGB\nimage size: (128, 128)\nimage width: 128\nimage height: 128\nimage palette: None\nimage info: {}\nimage to array: (128, 128, 3)\nModel: \"model_6\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 128, 128, 3)  0                                            \n__________________________________________________________________________________________________\nencoder_conv_1 (Conv2D)         (None, 64, 64, 32)   896         encoder_input[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 32)   0           encoder_conv_1[0][0]             \n__________________________________________________________________________________________________\nencoder_conv_2 (Conv2D)         (None, 32, 32, 64)   18496       leaky_re_lu_5[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 64)   0           encoder_conv_2[0][0]             \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 65536)        0           leaky_re_lu_6[0][0]              \n__________________________________________________________________________________________________\noutpost (Dense)                 (None, 1024)         67109888    flatten_2[0][0]                  \n__________________________________________________________________________________________________\nmu (Dense)                      (None, 200)          205000      outpost[0][0]                    \n__________________________________________________________________________________________________\nlog_var (Dense)                 (None, 200)          205000      outpost[0][0]                    \n__________________________________________________________________________________________________\nencoder_output (Lambda)         (None, 200)          0           mu[0][0]                         \n                                                                 log_var[0][0]                    \n==================================================================================================\nTotal params: 67,539,280\nTrainable params: 67,539,280\nNon-trainable params: 0\n__________________________________________________________________________________________________\nimage to array after expand: (1, 128, 128, 3)\n(128, 128, 3)\n[[[ 0.00682325  0.00078213 -0.00402496]\n  [ 0.00160062  0.001648    0.00041249]\n  [ 0.00148849  0.0014861   0.00110736]\n  ...\n  [ 0.00219431  0.00065296  0.00232431]\n  [ 0.00120672  0.00086255  0.00183411]\n  [ 0.00191304  0.00082442  0.00046959]]\n\n [[ 0.00439275  0.00345815  0.00293228]\n  [ 0.00593134  0.00220776  0.00065526]\n  [ 0.00164892  0.00118165  0.00167433]\n  ...\n  [ 0.00191612  0.00072742  0.00137194]\n  [ 0.00123675  0.00153493  0.00221597]\n  [ 0.00358988  0.00218696  0.00112365]]\n\n [[ 0.00123795  0.00104875  0.00132934]\n  [ 0.00163305  0.00177828  0.00244715]\n  [ 0.00391166  0.00294326  0.00272457]\n  ...\n  [ 0.00242077  0.00244861  0.00211342]\n  [ 0.00347429  0.00281256  0.00248452]\n  [ 0.00315501  0.00392497  0.00127989]]\n\n ...\n\n [[ 0.00154335  0.00049342  0.00104082]\n  [ 0.00236053  0.00111316  0.00123499]\n  [ 0.003968    0.00255428  0.00220454]\n  ...\n  [ 0.00218984  0.00118236  0.00045105]\n  [ 0.00191153  0.00204293  0.00156879]\n  [ 0.00251435  0.00181399  0.000921  ]]\n\n [[ 0.00123795  0.00104875  0.00132934]\n  [ 0.00163305  0.00177828  0.00244715]\n  [ 0.00391166  0.00294326  0.00272457]\n  ...\n  [ 0.00206237  0.00210563  0.00235281]\n  [ 0.00249274  0.00276652  0.00274835]\n  [ 0.0017221   0.00211217  0.00197594]]\n\n [[ 0.00428891  0.00245686 -0.00416878]\n  [ 0.00080625  0.00214386 -0.00173819]\n  [ 0.00256022  0.00135725  0.00119756]\n  ...\n  [ 0.00165626 -0.00125939  0.00071913]\n  [ 0.00434156  0.000448    0.00134335]\n  [ 0.00439603 -0.00455448  0.0025306 ]]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL.ImageShow import show\n",
    "\n",
    "image_path = '/Volumes/My Passport/PFM/output/training_png/Week9_39301_G11_4_Cells_34.png'\n",
    "\n",
    "img = Image.open(image_path)\n",
    "array_img  = img_to_array(img) # keras\n",
    "\n",
    "array_img = array_img / 256.\n",
    "\n",
    "#print(array_img)\n",
    "\n",
    "img.show()\n",
    "\n",
    "print('image format: ' + str(img.format))\n",
    "#print('image shape: ' + str(img.shape))\n",
    "print('image mode: ' + img.mode)\n",
    "print('image size: ' + str(img.size))\n",
    "print('image width: ' + str(img.width))\n",
    "print('image height: ' + str(img.height))\n",
    "print('image palette: ' + str(img.palette))\n",
    "print('image info: ' + str(img.info))\n",
    "\n",
    "print('image to array: ' + str(array_img.shape))\n",
    "\n",
    "array_img = np.expand_dims(array_img, axis=0)\n",
    "\n",
    "\n",
    "vae.encoder.summary()\n",
    "\n",
    "print('image to array after expand: ' + str(array_img.shape))\n",
    "\n",
    "z_result = vae.encoder.predict(array_img)\n",
    "reco = vae.decoder.predict(z_result).squeeze()\n",
    "\n",
    "#print(reco)\n",
    "\n",
    "print(reco.shape)\n",
    "\n",
    "# scaled\n",
    "outimg = array_to_img(reco)\n",
    "\n",
    "show(outimg)\n",
    "\n",
    "print(reco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
