{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from model.VariationalAutoencoder import VariationalAutoencoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, save_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = os.environ.get('HOME') + '/model3'\n",
    "FILE_MODEL = 'weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder()\n",
    "vae.model.load_weights(os.path.join(MODEL_FOLDER, 'weights.h5'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image format: PNG\nimage mode: RGB\nimage size: (128, 128)\nimage width: 128\nimage height: 128\nimage palette: None\nimage info: {}\nimage to array: (128, 128, 3)\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 128, 128, 3)  0                                            \n__________________________________________________________________________________________________\nencoder_conv_1 (Conv2D)         (None, 64, 64, 32)   896         encoder_input[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 32)   0           encoder_conv_1[0][0]             \n__________________________________________________________________________________________________\nencoder_conv_2 (Conv2D)         (None, 32, 32, 64)   18496       leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 64)   0           encoder_conv_2[0][0]             \n__________________________________________________________________________________________________\nencoder_conv_3 (Conv2D)         (None, 16, 16, 64)   36928       leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 64)   0           encoder_conv_3[0][0]             \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 16384)        0           leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\noutpost (Dense)                 (None, 4096)         67112960    flatten_1[0][0]                  \n__________________________________________________________________________________________________\nmu (Dense)                      (None, 200)          819400      outpost[0][0]                    \n__________________________________________________________________________________________________\nlog_var (Dense)                 (None, 200)          819400      outpost[0][0]                    \n__________________________________________________________________________________________________\nencoder_output (Lambda)         (None, 200)          0           mu[0][0]                         \n                                                                 log_var[0][0]                    \n==================================================================================================\nTotal params: 68,808,080\nTrainable params: 68,808,080\nNon-trainable params: 0\n__________________________________________________________________________________________________\nimage to array after expand: (1, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n[[[ 5.16063906e-03  1.84085779e-03 -4.66583483e-03]\n  [ 2.19300017e-03 -4.47656028e-04 -1.12136081e-03]\n  [ 1.09537132e-03 -4.47094906e-04 -1.95633620e-04]\n  ...\n  [ 2.91783363e-04 -7.32385088e-04 -2.66667455e-04]\n  [ 8.20700079e-05 -9.48917121e-04 -1.65261328e-04]\n  [ 1.01856887e-03 -7.86175951e-04 -1.12435967e-03]]\n\n [[ 1.37223303e-03  1.36149349e-03 -1.07144937e-03]\n  [-9.67402011e-05 -3.87595268e-04  2.75148079e-03]\n  [ 7.38462433e-04 -1.32904388e-05  2.56534666e-04]\n  ...\n  [ 9.64440405e-05 -7.18115130e-04  5.65864146e-04]\n  [-4.19128686e-04 -1.21639902e-03 -3.31290066e-04]\n  [ 2.83636153e-04 -2.60745874e-04  1.58237293e-03]]\n\n [[ 6.99073076e-04 -1.61364209e-04  9.32477415e-04]\n  [ 1.95872039e-04  2.41106376e-04  8.21568072e-04]\n  [ 2.20055506e-03 -1.47288665e-05 -2.12918967e-04]\n  ...\n  [ 6.64010644e-04 -9.28968657e-04 -1.14072114e-04]\n  [ 7.73951411e-04 -9.62502323e-04 -6.12348318e-04]\n  [-2.11082399e-04 -1.13568502e-03 -5.50303608e-04]]\n\n ...\n\n [[-6.77617267e-04 -7.82919349e-04 -2.70940363e-04]\n  [-7.37227499e-04 -5.75753860e-04  3.01495194e-04]\n  [-9.48574394e-04 -1.36302365e-03 -6.98052347e-04]\n  ...\n  [ 1.93345360e-03 -1.27632171e-04  6.00267202e-04]\n  [ 1.64911896e-03 -4.43682773e-04  1.27665699e-05]\n  [-3.96657735e-04 -7.64199300e-04 -6.62170351e-05]]\n\n [[ 3.29822302e-04 -8.11155420e-04  2.30178237e-04]\n  [-1.15480274e-04 -9.14686359e-04  2.18030065e-04]\n  [ 2.90825963e-04 -1.34214945e-03 -6.04774803e-04]\n  ...\n  [ 2.46274099e-03 -3.39790247e-04  5.42514026e-05]\n  [ 2.68624909e-03 -4.13257629e-04 -1.09713525e-04]\n  [-7.14100897e-05 -1.00497110e-03 -2.94826925e-04]]\n\n [[ 8.68100673e-04  1.00232195e-04 -2.93004513e-03]\n  [ 1.88573450e-03  8.57275911e-04  3.82050872e-04]\n  [-7.44435936e-04 -8.60506203e-04  8.41990113e-05]\n  ...\n  [ 5.16483560e-04 -4.55775298e-04  3.76626849e-05]\n  [ 8.47620890e-04 -1.83285680e-04  3.27549875e-04]\n  [ 3.72841954e-03  1.26348715e-03 -1.61177665e-03]]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL.ImageShow import show\n",
    "\n",
    "#image_path = '/Volumes/My Passport/PFM/output/training_png/Week9_39301_G11_4_Cells_34.png'\n",
    "#image_path = '/Volumes/My Passport/PFM/output/training_png/Week5_28921_B02_2_Cells_13.png'\n",
    "#image_path = '/Volumes/My Passport/PFM/output/training_png/Week5_28921_B02_3_Cells_39.png'\n",
    "image_path = '/Volumes/My Passport/PFM/output/training_png/Week7_34641_B02_1_Cells_28.png'\n",
    "\n",
    "img = Image.open(image_path)\n",
    "array_img  = img_to_array(img) # keras\n",
    "\n",
    "#array_img = array_img / 256.\n",
    "\n",
    "#print(array_img)\n",
    "\n",
    "img.show()\n",
    "\n",
    "print('image format: ' + str(img.format))\n",
    "#print('image shape: ' + str(img.shape))\n",
    "print('image mode: ' + img.mode)\n",
    "print('image size: ' + str(img.size))\n",
    "print('image width: ' + str(img.width))\n",
    "print('image height: ' + str(img.height))\n",
    "print('image palette: ' + str(img.palette))\n",
    "print('image info: ' + str(img.info))\n",
    "\n",
    "print('image to array: ' + str(array_img.shape))\n",
    "\n",
    "array_img = np.expand_dims(array_img, axis=0)\n",
    "\n",
    "\n",
    "vae.encoder.summary()\n",
    "\n",
    "print('image to array after expand: ' + str(array_img.shape))\n",
    "\n",
    "z_result = vae.encoder.predict(array_img)\n",
    "reco = vae.decoder.predict(z_result).squeeze()\n",
    "\n",
    "#print(reco)\n",
    "\n",
    "print(reco.shape)\n",
    "\n",
    "# scaled\n",
    "outimg = array_to_img(reco, scale=True)\n",
    "\n",
    "show(outimg)\n",
    "\n",
    "print(reco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
